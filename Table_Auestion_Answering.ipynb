{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Table Question Answering\n",
        "\n",
        "Given a bank statement table or any relational data stored in a structured format in a database, the user should be able to chat and ask questions from the data.\n",
        "\n",
        "For example, consider a sample bank statement (assume it is present in a readable format). The following sample queries could be asked by the user:\n",
        "\n",
        "a) **How much is my spend on online shopping?**\n",
        "  - *Expected answer:* Should fetch spends from e-commerce websites such as Amazon, Myntra, etc.\n",
        "\n",
        "b) **How much money have I spent on food and travel?**\n",
        "  - *Expected answer:* Should fetch items from payments at hotels, restaurants, online food delivery portals, etc.\n",
        "\n",
        "## Solutions\n",
        "\n",
        "### Solution 1\n",
        "1. Segregate table columns into two sets:\n",
        "  - a. Direct inbuilt filters\n",
        "  - b. Custom filters\n",
        "2. Design custom filters.\n",
        "3. Generate SQL queries corresponding to each query using an LLM by providing the table schema and available custom filter functions.\n",
        "4. Run the generated SQL query on the table.\n",
        "\n",
        "### Solution 2\n",
        "1. Instead of using SQL language, generate Python queries using pandas.\n",
        "\n",
        "### Solution 2 in Detail\n",
        "\n",
        "1. **Segregate TABLE columns into two sets:**\n",
        "  1. **Read table document and collect information corresponding to each column using preprocessing Python code:**\n",
        "    - Collect each column's information including column name, data type, some sample values, and unique values.\n",
        "    - Categorize the columns into two sets either manually or by asking an LLM:\n",
        "      1. **direct_columns:** Columns where direct filters will be applied.\n",
        "      2. **custom_columns:** Columns that require custom functions to filter.\n",
        "\n",
        "2. **Design Custom Filters:**\n",
        "  1. **Design a filter function \"custom_filter\" for custom_columns:**\n",
        "    - The function takes three arguments: dataframe, column_name, and filter_value to filter rows. Example:\n",
        "    ```python\n",
        "    def custom_filter(df, description, filter_value):\n",
        "        df = df[df['description'].str.contains(filter_value)]\n",
        "        return df\n",
        "    ```\n",
        "  2. **Custom filter design is dependent on use cases:**\n",
        "    1. **Filtering text by keyword search (e.g., regex, BM25):**\n",
        "        - Applicable when columns contain some small description about products, like \"high neckline dress in blue color made of cotton.\"\n",
        "    2. **Filtering text by semantic meaning using an embedding model or LLM:**\n",
        "      1. Applicable for our problem statement. This step is the main bottleneck for our problem statement.\n",
        "      2. Apply the embedding model on filter_value and description entry to check whether both are related based on similarity score.\n",
        "        - ```python\n",
        "          score = embed(filter_value) @ embed(df[custom_column][index])\n",
        "          ```\n",
        "        - Take if score > threshold else reject.\n",
        "      3. In some cases, embedding models are not good for comparing, especially for our case (e.g., most embedding models will fail to compare \"Flipkart\" to \"Shopping\"). In these cases, we need to fine-tune embedding models.\n",
        "      4. Or we need a lightweight LLM that has good world knowledge to tell whether these two are related or not.\n",
        "        - **Create prompt for LLM to filter, example prompt:**\n",
        "        ```markdown\n",
        "        You are provided sub-query and search database.\n",
        "        Your task is to select ids from database which are related to sub-query. Output should be list of ids without any explanation.\n",
        "        if no ids found, return empty list.\n",
        "        ### Sub-query:\n",
        "        food\n",
        "        ### Database:\n",
        "        {0: '550274051211 CHB', 1: 'CALL REF NO 3442 FROM A/C 22222222', 2: 'Amazon', 3: 'Tebay Trading Co', 4: 'Morrisons Petrol', 5: 'Business Loan', 6: 'James White Media', 7: 'ATM High Street', 8: 'Acom Advertising Studies', 9: 'Marriott Hotel'}\n",
        "        ```\n",
        "      5. If we know the range of filter_values in advance, we can map custom columns to dummy columns using embedding models or LLM. This will save a lot of time to filter.\n",
        "\n",
        "3. **Generate Python pandas queries corresponding to the query using LLM by giving table schema and custom filter functions available:**\n",
        "  1. **Create prompt for LLM which includes the table schema and custom filter function schema, and instructions to generate code:**\n",
        "    - The table schema contains column name, data type, and some short text about the purpose of each column.\n",
        "    - The filter function schema contains when to call this function and arguments to pass.\n",
        "\n",
        "  **Example prompt:**\n",
        "  ```markdown\n",
        "  You are a chatbot designed to interact with a table to fetch information based on user questions. The table has the following columns with their data types:\n",
        "  - Date: Text\n",
        "  - Type: Text\n",
        "  - Description: Text\n",
        "  - Paid In: Float\n",
        "  - Paid Out: Float\n",
        "  - Balance: Float\n",
        "\n",
        "  Based on the above structure, when a user asks a question, generate an appropriate pandas query code to fetch the relevant information from the database. Separate each filter code with a new line.\n",
        "  For the column \"Description\", call a function \"custom_filter(data_frame: pandas dataframe, column_name: here Description, sub_query: related sub-query)\".\n",
        "  Example:\n",
        "  ### Query:\n",
        "  How much is my spend on online shopping?\n",
        "  ### Generated code:\n",
        "  ``\n",
        "  df1 = df[df['Paid Out'] > 0]\n",
        "  df2 = custom_filter(df1, 'Description', 'online shopping')\n",
        "  amount = df2['Paid Out'].sum()\n",
        "  print(\"Amount Spent: \", amount)\n",
        "  ``\n",
        "  Don't write 'read_csv' and 'custom_filter' code by yourself, it's already there.\n",
        "  ### Here is the query:\n",
        "  {query}\n",
        "  ```\n",
        "\n",
        "4. **Parse and run this generated code using some text code executer like \"ast\".**\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "aajO2GEP6Wsu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Data Analysis to segregate TABLE columns into two sets."
      ],
      "metadata": {
        "id": "gwsAo-XpXdUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv('2024-06-29_21-33_table.csv',encoding='unicode_escape')\n",
        "\n",
        "# Iterate over each column\n",
        "for column in df.columns:\n",
        "\n",
        "    # Get the unique values in the column\n",
        "    unique = df[column].unique()\n",
        "    unique = pd.Series(unique).dropna().unique()\n",
        "\n",
        "    if len(unique)>5:\n",
        "      unique_values = random.sample(list(unique),3)\n",
        "    else:\n",
        "      unique_values = list(unique)\n",
        "    dtype= 'str'\n",
        "\n",
        "    try:\n",
        "      x=[int(i) for i in unique if i]\n",
        "      dtype ='int'\n",
        "    except:\n",
        "      pass\n",
        "    # Print the column name, data type, and unique values\n",
        "    print(f\"Column: {column}\")\n",
        "    print(f\"Data Type: {dtype}\")\n",
        "    print(f\"Example Values: {unique_values}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OE2k5sFauaYN",
        "outputId": "2edf2d8d-8a51-48f3-b1e2-03955295b303"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column: Date\n",
            "Data Type: str\n",
            "Example Values: ['01 Dec 2014', '24 Oct 2014', '01 Nov 2014']\n",
            "\n",
            "Column: Type\n",
            "Data Type: str\n",
            "Example Values: ['DIGITAL BANKING', 'Int Bank', 'BACS']\n",
            "\n",
            "Column: Description\n",
            "Data Type: str\n",
            "Example Values: ['James White Media', '550274051211 CHB', 'Various Payment']\n",
            "\n",
            "Column: Paid In\n",
            "Data Type: int\n",
            "Example Values: [20000.0, 9.33]\n",
            "\n",
            "Column: Paid Out\n",
            "Data Type: int\n",
            "Example Values: [280.0, 515.22, 190.4]\n",
            "\n",
            "Column: Balance\n",
            "Data Type: int\n",
            "Example Values: [1613.5, 16535.21, 18034.43]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Design Custom filter function"
      ],
      "metadata": {
        "id": "zqpxi9yZYfcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "def custom_filter_(data_frame, column_name, sub_query, **kwargs):\n",
        "    database = data_frame[column_name].dropna().unique()\n",
        "    batch_size = 10\n",
        "    ids_final = []\n",
        "\n",
        "    for i in range(0, len(database), batch_size):\n",
        "        batch = database[i:i + batch_size]\n",
        "        database_dict = {i + idx: item for idx, item in enumerate(batch)}\n",
        "        prompt_template = kwargs['prompt_template']\n",
        "        prompt = prompt_template.format(sub_query=sub_query, database=str(database_dict))\n",
        "        #print(prompt)\n",
        "        api_response = get_completion(\n",
        "            [{\"role\": \"user\", \"content\": prompt}],\n",
        "            model=\"gpt-4\"\n",
        "        )\n",
        "\n",
        "        ids = api_response.choices[0].message.content\n",
        "        try:\n",
        "            ids = json.loads(ids)\n",
        "        except json.JSONDecodeError:\n",
        "            ids = []\n",
        "        #print(ids)\n",
        "        ids_final.extend(ids)\n",
        "\n",
        "    filtered_list = database[ids_final]\n",
        "    filtered_data_frame = data_frame[data_frame[column_name].isin(filtered_list)]\n",
        "\n",
        "    print(f\"\\nList of transactions for {sub_query}:\")\n",
        "    for col in filtered_data_frame.columns:\n",
        "        print(f\"{col:<15}\", end=' ')\n",
        "    print()\n",
        "\n",
        "    for index, row in filtered_data_frame.iterrows():\n",
        "        for col in row:\n",
        "            print(f\"{col:<15}\", end=' ')\n",
        "        print()\n",
        "\n",
        "    print('\\n\\n')\n",
        "    return filtered_data_frame\n",
        "\n"
      ],
      "metadata": {
        "id": "BeWXUj--ECQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UyRHa_DmS3cu",
        "outputId": "80993273-0e03-45e1-93c3-a8676b677e4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.35.7-py3-none-any.whl (327 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.5/327.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3 & 4: Generate Python pandas queries corresponding to the query using LLM and run."
      ],
      "metadata": {
        "id": "3OOlhQhrcxrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "\n",
        "PROMPT1 = \"\"\"\n",
        "You are a chatbot designed to interact with a table to fetch information based on user questions. The table contains has following columns with thier datatype:\n",
        "Date: Text, Type: Text, Description: Text, Paid In: Float, Paid Out: Float, Balance: Float\n",
        "\n",
        "Based on the above structure, when a user asks a question, generate an appropriate pandas query code to fetch the relevant information from the database. Separate each filter code with a new line.\n",
        "For column \"Description\" call a funtion \"custom_filter(data_frame: pandas dataframe, column_name: here Description, sub_query: related sub-query)\".\n",
        "  example:\n",
        "    query:\n",
        "      How much is my spend on online shopping?\n",
        "    generated code:\n",
        "      ```python\n",
        "         df1 = df[df['Paid Out]'>0]\n",
        "         df2 = custom_filter(df1, 'Description', 'online shoping')\n",
        "         amount = df2['Paid Out'].sum()\n",
        "         print(\"Amount Spend: \",amount)\n",
        "      ```\n",
        "\n",
        "Don't write 'read_csv' and 'custom_filter' code by yourself, it's already there.\n",
        "\n",
        "### Here is the query:\n",
        "    {query}\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "PROMPT2=\"\"\"You are provided sub-query and search database.\n",
        "           Your task is to select ids from database which are related to sub-query. Output should be list of ids without any explanation.\n",
        "           if no ids found, return empty list.\n",
        "           ### Sub-query:\n",
        "               {sub_query}\n",
        "           ### Database:\n",
        "               {database}\n",
        "           \"\"\"\n"
      ],
      "metadata": {
        "id": "LOzCTJYJtPb-",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "api_key = \"sk-..\"\n",
        "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\", api_key))\n",
        "\n",
        "\n",
        "def get_completion(\n",
        "    messages: list[dict[str, str]],\n",
        "    model: str = \"gpt-4\",\n",
        "    max_tokens=500,\n",
        "    temperature=0,\n",
        "    stop=None,\n",
        "    seed=123,\n",
        "    tools=None,\n",
        "    logprobs=None,\n",
        "    top_logprobs=None,\n",
        ") -> str:\n",
        "    params = {\n",
        "        \"model\": model,\n",
        "        \"messages\": messages,\n",
        "        \"max_tokens\": max_tokens,\n",
        "        \"temperature\": temperature,\n",
        "        \"stop\": stop,\n",
        "        \"seed\": seed,\n",
        "        \"logprobs\": logprobs,\n",
        "        \"top_logprobs\": top_logprobs,\n",
        "    }\n",
        "    if tools:\n",
        "        params[\"tools\"] = tools\n",
        "\n",
        "    completion = client.chat.completions.create(**params)\n",
        "    return completion"
      ],
      "metadata": {
        "id": "JEymCIhNpZzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import ast\n",
        "from functools import partial\n",
        "\n",
        "queries= [\"How much money i have spent on food and travel\",\n",
        "          \"How much is my spend on online shopping\",\n",
        "          \"How much is my balance now\",\n",
        "          \"How much balance got credited in my account\",\n",
        "          \"My spending on Hotels only\"]\n",
        "\n",
        "for query in queries[:]:\n",
        "  print(\"*\"*100,'\\n')\n",
        "  print(f\"Query Asked: {query}\\n\")\n",
        "  custom_filter= partial(custom_filter_, query=query, prompt_template=PROMPT2)\n",
        "  prompt= PROMPT1.format(query=query)\n",
        "  api_response = get_completion(\n",
        "          [{\"role\": \"user\", \"content\": prompt}],\n",
        "          model=\"gpt-4\",\n",
        "      )\n",
        "  response = api_response.choices[0].message.content\n",
        "\n",
        "\n",
        "  pattern = re.compile(r'```python\\n(.*?)```', re.DOTALL)\n",
        "  match = pattern.search(response)\n",
        "  if match:\n",
        "      code = match.group(1)\n",
        "      print(f\"Generated code:\\n{code}\\n\")\n",
        "      tree = ast.parse(code)\n",
        "      compiled = compile(tree, filename=\"<ast>\", mode=\"exec\")\n",
        "      exec(compiled, None, None)\n",
        "  else:\n",
        "      print(\"No code found in the response.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nei45grrr1J8",
        "outputId": "2ecb4ec6-ebb4-4a58-856e-8be67646883d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************************************************************************************************** \n",
            "\n",
            "Query Asked: How much money i have spent on food and travel\n",
            "\n",
            "Generated code:\n",
            "df1 = df[df['Paid Out']>0]\n",
            "df2 = custom_filter(df1, 'Description', 'food')\n",
            "df3 = custom_filter(df1, 'Description', 'travel')\n",
            "amount = df2['Paid Out'].sum() + df3['Paid Out'].sum()\n",
            "print(\"Amount Spent: \", amount)\n",
            "\n",
            "\n",
            "\n",
            "List of transactions for food:\n",
            "Date            Type            Description     Paid In         Paid Out        Balance         \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "List of transactions for travel:\n",
            "Date            Type            Description     Paid In         Paid Out        Balance         \n",
            "01 Nov 2014     BACS            Marriot Hotel   nan             177.0           18034.43        \n",
            "01 Nov 2014     Fastor Payment  Abellio Scotrail Ltd nan             122.22          17857.43        \n",
            "\n",
            "\n",
            "\n",
            "Amount Spent:  299.22\n",
            "**************************************************************************************************** \n",
            "\n",
            "Query Asked: How much is my spend on online shopping\n",
            "\n",
            "Generated code:\n",
            "df1 = df[df['Paid Out']>0]\n",
            "df2 = custom_filter(df1, 'Description', 'online shopping')\n",
            "amount = df2['Paid Out'].sum()\n",
            "print(\"Amount Spend: \",amount)\n",
            "\n",
            "\n",
            "\n",
            "List of transactions for online shopping:\n",
            "Date            Type            Description     Paid In         Paid Out        Balance         \n",
            "24 Oct 2014     Faster Payment  Amazon          nan             132.3           1473.5          \n",
            "24 Oct 2014     BACS            Tebay Trading Co nan             515.22          1341.2          \n",
            "\n",
            "\n",
            "\n",
            "Amount Spend:  647.52\n",
            "**************************************************************************************************** \n",
            "\n",
            "Query Asked: How much is my balance now\n",
            "\n",
            "Generated code:\n",
            "current_balance = df['Balance'].iloc[-1]\n",
            "print(\"Current Balance: \", current_balance)\n",
            "\n",
            "\n",
            "Current Balance:  2548.14\n",
            "**************************************************************************************************** \n",
            "\n",
            "Query Asked: How much balance got credited in my account\n",
            "\n",
            "Generated code:\n",
            "df1 = df[df['Paid In']>0]\n",
            "balance_credited = df1['Paid In'].sum()\n",
            "print(\"Balance Credited: \",balance_credited)\n",
            "\n",
            "\n",
            "Balance Credited:  20009.33\n",
            "**************************************************************************************************** \n",
            "\n",
            "Query Asked: My spending on Hotels only\n",
            "\n",
            "Generated code:\n",
            "df1 = df[df['Paid Out']>0]\n",
            "df2 = custom_filter(df1, 'Description', 'Hotels')\n",
            "amount = df2['Paid Out'].sum()\n",
            "print(\"Amount Spend: \",amount)\n",
            "\n",
            "\n",
            "\n",
            "List of transactions for Hotels:\n",
            "Date            Type            Description     Paid In         Paid Out        Balance         \n",
            "01 Nov 2014     BACS            Marriot Hotel   nan             177.0           18034.43        \n",
            "\n",
            "\n",
            "\n",
            "Amount Spend:  177.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Discussion:\n",
        "\n",
        "1. Since I don't have GPUs to run open-source LLMs like Mistral and LLaMA, I used the GPT-4 API.\n",
        "\n",
        "2. Due to time constraints and accuracy concerns, I extracted \"custom columns\" like \"Description\" manually instead of using an LLM to decide them. Utilizing an LLM would make it more adaptable for any table. I also prepared prompts manually, which can also be automated using an LLM.\n",
        "\n",
        "3. The main challenge was associating the query with the description columns.\n",
        "   1. I tried embedding models like 'all-minilm-l6-v2' and 'BAAI/bge-m3', but these models are trained to capture similar meaning sentences, not for entity relationships in a knowledge graph, so their performance was poor.\n",
        "   2. I searched for knowledge graph embedding models but couldn't find any suitable ones.\n",
        "   3. Due to limited time, I experimented with filtering using GPT-4, which worked well. GPT-4 has good world knowledge, such as knowing that \"Abellio ScotRail\" is a train company and associating it with \"travel.\"\n",
        "   4. I applied GPT-4 to unique values of the \"Description\" column in batches of 10 (i.e., 1 LLM call would compare the subquery 'travel' with 10 description values).\n",
        "   5. LLM calls are not scalable and can be costly for 10k unique values. The best approach would be to fine-tune embedding models on data that contain entity relationships as well as similar sentences.\n",
        "\n",
        "4. Since I know basic SQL, I chose to generate queries in Python instead of SQL so that I could debug things easily. However, for production, we need to implement it in SQL.\n",
        "\n",
        "5. This is a basic demo. To handle all limitations and make it production-ready, we need time to conduct R&D on each component of the system.\n",
        "\n",
        "6. There might be other approaches to achieve this, which I haven't explored."
      ],
      "metadata": {
        "id": "PgdSl1mIkElW"
      }
    }
  ]
}